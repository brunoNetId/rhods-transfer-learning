{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20a0971",
   "metadata": {
    "id": "e20a0971"
   },
   "source": [
    "# Building an Image Classifier Deep Network applying Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1b796-5d74-4b97-aae4-7fe33a7fc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mount_path = os.environ['working_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8wM31kI5-PeJ",
   "metadata": {
    "id": "8wM31kI5-PeJ"
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import tf.keras.utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad8bd9",
   "metadata": {
    "id": "42ad8bd9"
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58f9b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d58f9b25",
    "outputId": "e8fb47f7-64a8-4912-81cb-3f4f6bc2deec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 files belonging to 2 classes.\n",
      "Using 147 files for training.\n",
      "Found 183 files belonging to 2 classes.\n",
      "Using 36 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# dataset's directory path\n",
    "# directory = \"./images/\"\n",
    "directory = mount_path+\"images/\"\n",
    "\n",
    "batch_size = 32\n",
    "image_size = (160,160) # resize the images to 160x160\n",
    "\n",
    "# create training and validation sets\n",
    "# use image_dataset_from_directory to load the images\n",
    "# set a validation split and specify the subset ('training' or 'validation')\n",
    "# set the random seeds to match eachother (to avoid overlapping of the images in\n",
    "# train and validation sets)\n",
    "\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                             seed=42)\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='validation',\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e4364d-4e79-4f34-ad2b-7a66447040ea",
   "metadata": {},
   "source": [
    "# Obtain Class names (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Af79dbaPaA6Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Af79dbaPaA6Z",
    "outputId": "c123d6d9-e133-4b73-819d-9d8e9e3ecc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea-earl-grey', 'tea-lemon']\n"
     ]
    }
   ],
   "source": [
    "# print some images\n",
    "# use .class_names attribute to retrieve the classes of the images from the dicrectories names\n",
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58fc24",
   "metadata": {
    "id": "eb58fc24",
    "tags": []
   },
   "source": [
    "# Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "717277b5",
   "metadata": {
    "id": "717277b5"
   },
   "outputs": [],
   "source": [
    "# load the pre-trained model without the final layers\n",
    "image_shape = image_size + (3,)\n",
    "pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43dbb801-a26f-49e5-82af-f90abbed99f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_trained_model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3b5cc-209a-44f3-929b-9be181ff6aa9",
   "metadata": {},
   "source": [
    "# Preprocessing layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38593a1f-30d5-4c52-937e-8163e2c1ee62",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d413de-1799-47b0-b32c-6d50af6b3196",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a2c74-499c-4361-8d71-8639f8db7222",
   "metadata": {},
   "source": [
    "# Plot Loss/Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d073e25-75ad-4fdd-b55c-c38e451444be",
   "metadata": {},
   "source": [
    "# Verify Tea Lemon prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d610fd-745c-42b8-8619-fcfe87bd6e75",
   "metadata": {},
   "source": [
    "# Verify Tea Earl-Grey prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b87367",
   "metadata": {
    "id": "12b87367"
   },
   "source": [
    "# With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "713011b6",
   "metadata": {
    "id": "713011b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# freeze the base model by making it non trainable\n",
    "pre_trained_model.trainable = False\n",
    "# define the input layer\n",
    "inputs = tf.keras.Input(shape=image_shape) \n",
    "# apply data augmentation\n",
    "x = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal'),\n",
    "                         tf.keras.layers.RandomRotation(0.2)])(inputs)\n",
    "\n",
    "# preprocess the augmented inputs\n",
    "x = preprocess_input(x)\n",
    "# add the pre-trained (not trainable) model\n",
    "x = pre_trained_model(x, training=False)\n",
    "# add a pooling layer\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# add a dropout layer for regularization\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# add the output layer\n",
    "# outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "# outputs = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "# outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n",
    "outputs = tf.keras.layers.Dense(len(class_names), activation='sigmoid')(x)\n",
    "# define the model with its inputs and outputs\n",
    "model_augmented = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c62c8e",
   "metadata": {
    "id": "03c62c8e",
    "outputId": "19df7dc7-c3bc-4565-9ea0-6fcb2cb92c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLamb  (None, 160, 160, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLam  (None, 160, 160, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " mobilenetv2_1.00_160 (Funct  (None, 5, 5, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_augmented.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8cbc86-ecb2-4d86-849d-a93eaff13c50",
   "metadata": {},
   "source": [
    "# Compile augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbcb7e19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbcb7e19",
    "outputId": "63ca846a-0374-4f41-ddb1-da02aa329c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 7s 458ms/step - loss: 0.6819 - accuracy: 0.6190 - val_loss: 0.5371 - val_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 3s 290ms/step - loss: 0.4947 - accuracy: 0.8095 - val_loss: 0.3675 - val_accuracy: 0.8056\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 3s 289ms/step - loss: 0.4289 - accuracy: 0.8163 - val_loss: 0.2939 - val_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 3s 287ms/step - loss: 0.2863 - accuracy: 0.8639 - val_loss: 0.2629 - val_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 3s 299ms/step - loss: 0.2113 - accuracy: 0.9116 - val_loss: 0.2561 - val_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 3s 304ms/step - loss: 0.2088 - accuracy: 0.9184 - val_loss: 0.2461 - val_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 3s 302ms/step - loss: 0.1701 - accuracy: 0.9456 - val_loss: 0.2320 - val_accuracy: 0.8889\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 3s 315ms/step - loss: 0.1787 - accuracy: 0.9456 - val_loss: 0.2103 - val_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 3s 279ms/step - loss: 0.1472 - accuracy: 0.9728 - val_loss: 0.1945 - val_accuracy: 0.9722\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 4s 315ms/step - loss: 0.1426 - accuracy: 0.9524 - val_loss: 0.1890 - val_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 4s 360ms/step - loss: 0.1165 - accuracy: 0.9592 - val_loss: 0.1876 - val_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 4s 282ms/step - loss: 0.1079 - accuracy: 0.9660 - val_loss: 0.1829 - val_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 3s 285ms/step - loss: 0.1185 - accuracy: 0.9728 - val_loss: 0.1675 - val_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 3s 306ms/step - loss: 0.1097 - accuracy: 0.9456 - val_loss: 0.1628 - val_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 3s 305ms/step - loss: 0.0781 - accuracy: 0.9796 - val_loss: 0.1651 - val_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 3s 306ms/step - loss: 0.0909 - accuracy: 0.9796 - val_loss: 0.1421 - val_accuracy: 0.9444\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 3s 285ms/step - loss: 0.0715 - accuracy: 0.9864 - val_loss: 0.1221 - val_accuracy: 0.9722\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 3s 285ms/step - loss: 0.0608 - accuracy: 0.9932 - val_loss: 0.1200 - val_accuracy: 0.9444\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 3s 294ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 3s 307ms/step - loss: 0.0823 - accuracy: 0.9728 - val_loss: 0.1406 - val_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "base_learning_rate = 0.001\n",
    "model_augmented.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              # loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# train the model\n",
    "history_augmented = model_augmented.fit(train_set, validation_data=validation_set, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a42f2-1279-4756-9b3b-9ff54b17e880",
   "metadata": {},
   "source": [
    "# test single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc2ca52d-1a0b-482c-acdb-7c58ce90742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.17160852 0.49986148]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# testfile = \"./images/tea-earl-grey/PXL_20230803_124233750.MP.jpg\"\n",
    "# testfile = \"./images/tea-lemon/PXL_20230803_153317298.jpg\"\n",
    "\n",
    "testfile = mount_path+\"images/tea-earl-grey/PXL_20230803_124233750.MP.jpg\"\n",
    "# testfile = mount_path+\"images/tea-lemon/PXL_20230803_153317298.jpg\"\n",
    "\n",
    "img = Image.open(testfile).convert('RGB')\n",
    "img = img.resize((160, 160), Image.LANCZOS)\n",
    "img = np.asarray(img)\n",
    "# print(img)\n",
    "\n",
    "mydata = np.empty((1, 160, 160, 3))\n",
    "mydata[0] = img\n",
    "\n",
    "# print(mydata)\n",
    "\n",
    "mypredition = model_augmented.predict(mydata)\n",
    "\n",
    "print(mypredition)\n",
    "print(np.argmax(mypredition, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3949cce-82f0-461b-b835-c79cb6672ac7",
   "metadata": {},
   "source": [
    "# Save augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "047586cf-fe51-4890-b556-5270146b3525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tea_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tea_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model_augmented, \"./models/tea_model/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b57d45-dd5e-4a87-a586-df776b297901",
   "metadata": {},
   "source": [
    "# Infer saved augmented model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7273a4-257e-44d8-9de1-adf63bd75741",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0040293-ff70-4743-a4b4-152b16d32055",
   "metadata": {},
   "source": [
    "### Obtain In/Out keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d3fcc-5d47-465d-a896-49a2560ff8d9",
   "metadata": {},
   "source": [
    "### Load image and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da411-d7f2-4394-93e2-cb4e97802a69",
   "metadata": {},
   "source": [
    "# Save model with Base64 Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77e99-4c19-4c51-8bc9-7f9ddd08bff9",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8ac7404-0aa1-4e61-928c-efee862219a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea-earl-grey', 'tea-lemon']\n",
      "tf.Tensor([[b'tea-earl-grey' b'tea-lemon']], shape=(1, 2), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(class_names)\n",
    "labels = tf.constant([class_names])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3219248-d436-42af-a996-387fd5bb1f83",
   "metadata": {},
   "source": [
    "### Load augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c2d1e9a-3735-4578-8df8-8896781e3b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction signature_wrapper(*, input_4)\n",
      "  Args:\n",
      "    input_4: float32 Tensor, shape=(None, 160, 160, 3)\n",
      "  Returns:\n",
      "    {'dense_1': <1>}\n",
      "      <1>: float32 Tensor, shape=(None, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tea_model_b64/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tea_model_b64/1/assets\n"
     ]
    }
   ],
   "source": [
    "smodel = tf.saved_model.load(\"./models/tea_model/1\")\n",
    "# smodel = model_augmented\n",
    "\n",
    "# This is the current signature, that only accepts image tensors as input\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "print(signature)\n",
    "\n",
    "# obtain the key name of the output (typically 'dense_X')\n",
    "keyOutput = next(iter(signature.structured_outputs))\n",
    "\n",
    "@tf.function()\n",
    "def my_predict(image_b64):\n",
    "\n",
    "    # get content\n",
    "    content = image_b64[0]\n",
    "    \n",
    "    # decode image    \n",
    "    image = tf.image.decode_jpeg(content,channels=3)\n",
    "    # tf.compat.v1.enable_eager_execution()\n",
    "    \n",
    "    # resize image\n",
    "    image = tf.image.resize(image, [160, 160])\n",
    "    \n",
    "    # expand dimension to match signature\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    # execute prediction\n",
    "    prediction = signature(image)\n",
    "\n",
    "    # obtain index of maximum probability prediction\n",
    "    idx = tf.argmax(prediction[keyOutput],axis=1)\n",
    "    \n",
    "    # obtain the label for given index\n",
    "    label = tf.gather(labels, idx, batch_dims=1)\n",
    "\n",
    "    # obtain probability from Tensor\n",
    "    probability = prediction[keyOutput][0,idx[0]]\n",
    "    \n",
    "    # combine result in String Tensor format with [label,probability]\n",
    "    result = tf.concat([label, [tf.as_string(probability)]], axis=0)\n",
    "    \n",
    "    # return result_tensor\n",
    "    return result\n",
    "\n",
    "# Create new signature, to read b64 images\n",
    "new_signature = my_predict.get_concrete_function(\n",
    "    image_b64=tf.TensorSpec(name=\"image_b64\", shape=[1], dtype=tf.string)\n",
    ")\n",
    "\n",
    "# Save model with Base64 input signature\n",
    "tf.saved_model.save(\n",
    "    smodel,\n",
    "    # export_dir=\"./models/tea_model_b64/1\",\n",
    "    export_dir=mount_path+\"models/tea_model_b64/1\",\n",
    "    signatures=new_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f2fac-5d8e-40f6-a8cc-b53671c1e978",
   "metadata": {},
   "source": [
    "# Test Base64 Model with single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3a9b5d9-3bfc-48e6-b13a-efd0df2a1040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction signature_wrapper(*, image_b64)\n",
      "  Args:\n",
      "    image_b64: string Tensor, shape=(1,)\n",
      "  Returns:\n",
      "    {'output_0': <1>}\n",
      "      <1>: string Tensor, shape=(2,)\n"
     ]
    }
   ],
   "source": [
    "# smodel = tf.saved_model.load(\"../models/tea_model_b64/1\")\n",
    "smodel = tf.saved_model.load(mount_path+\"models/tea_model_b64/1\")\n",
    "\n",
    "\n",
    "# Load model's signature\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbc0d5-70d9-4156-a6da-969a70a14aa4",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15e34858-5b74-4528-b631-9c66d8cfef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_0': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'tea-earl-grey', b'0.968096'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "# testfile = \"./images/tea-earl-grey/PXL_20230803_124233750.MP.jpg\"\n",
    "# testfile = \"./images/tea-lemon/PXL_20230803_153317298.jpg\"\n",
    "\n",
    "testfile = mount_path+\"images/tea-earl-grey/PXL_20230803_124233750.MP.jpg\"\n",
    "# testfile = mount_path+\"images/tea-lemon/PXL_20230803_153317298.jpg\"\n",
    "\n",
    "\n",
    "# load test image\n",
    "content = tf.io.read_file(testfile)\n",
    "\n",
    "# reshape to signature's expected dimensions\n",
    "content = tf.reshape(content, shape = [1])\n",
    "\n",
    "# print(tf.print(content, summarize=3))\n",
    "\n",
    "# obtain signature\n",
    "f = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "# run prediction\n",
    "myprediction = f(image_b64=content)\n",
    "print(myprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee7318-82e1-446a-88dd-0d714b9b610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a439b-87c9-4677-8d76-1c22726fb69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Alpaca image classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
