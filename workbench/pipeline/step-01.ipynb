{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20a0971",
   "metadata": {
    "id": "e20a0971"
   },
   "source": [
    "# Building an Image Classifier Deep Network applying Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a71cd6-355c-4e8b-8863-75eb49800798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "s3endpoint = os.environ['s3endpoint']\n",
    "s3bucket = os.environ['s3bucket_data']\n",
    "mount_path = os.environ['working_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8wM31kI5-PeJ",
   "metadata": {
    "id": "8wM31kI5-PeJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:22:23.721158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-15 09:22:24.735155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-15 09:22:24.735277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-15 09:22:24.735289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import tf.keras.utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b897d31-43f6-4b83-b719-6f326504f32a",
   "metadata": {},
   "source": [
    "# Clean data in PVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0633966f-7213-4579-9b5b-3f4746a54757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mount_path = \"/data/\"\n",
    "# mount_path = \"\"\n",
    "images_path = mount_path+\"images\"\n",
    "models_path = mount_path+\"models\"\n",
    "\n",
    "os.system(\"rm -rf \"+images_path)\n",
    "os.system(\"rm -rf \"+models_path)\n",
    "# os.system(\"ls \"+images_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a38e59-edce-49cb-b271-2d28edd7526f",
   "metadata": {},
   "source": [
    "# Data Retrieval from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e82e760-ea0c-4552-b39e-c736789d2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "# s3endpoint='https://minio-api-test02.apps.rhods-internal.61tk.p1.openshiftapps.com',\n",
    "# s3endpoint = \"https://minio-api-demo-ai.apps.cluster-ssfg4.dynamic.opentlc.com\"\n",
    "# s3bucket = \"data\"\n",
    "\n",
    "s3_client = boto3.client('s3',\n",
    "        endpoint_url=s3endpoint,\n",
    "        aws_access_key_id='minio',\n",
    "        aws_secret_access_key='minio123',\n",
    "        config=Config(signature_version='s3v4'),\n",
    "        region_name='us-east-1')\n",
    "\n",
    "\n",
    "objects = s3_client.list_objects_v2(Bucket=s3bucket)\n",
    "\n",
    "\n",
    "for obj in objects['Contents']:\n",
    "    print(obj['Key'])\n",
    "    # print(obj.key)\n",
    "    if not os.path.exists(os.path.dirname(mount_path+obj['Key'])):\n",
    "        os.makedirs(os.path.dirname(mount_path+obj['Key']))\n",
    "    s3_client.download_file(s3bucket,obj['Key'], mount_path+obj['Key'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Alpaca image classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
