{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20a0971",
   "metadata": {
    "id": "e20a0971"
   },
   "source": [
    "# Building an Image Classifier Deep Network applying Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8wM31kI5-PeJ",
   "metadata": {
    "id": "8wM31kI5-PeJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 10:05:51.180700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 10:05:53.042384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-13 10:05:53.042468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-13 10:05:53.042477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import tf.keras.utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad8bd9",
   "metadata": {
    "id": "42ad8bd9"
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58f9b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d58f9b25",
    "outputId": "e8fb47f7-64a8-4912-81cb-3f4f6bc2deec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 files belonging to 2 classes.\n",
      "Using 147 files for training.\n",
      "Found 183 files belonging to 2 classes.\n",
      "Using 36 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 10:06:05.448265: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-13 10:06:05.448298: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-13 10:06:05.448321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (testtl-0): /proc/driver/nvidia/version does not exist\n",
      "2023-11-13 10:06:05.450395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# dataset's directory path\n",
    "directory = \"../dataset/images/\"\n",
    "\n",
    "batch_size = 32\n",
    "image_size = (160,160) # resize the images to 160x160\n",
    "\n",
    "# create training and validation sets\n",
    "# use image_dataset_from_directory to load the images\n",
    "# set a validation split and specify the subset ('training' or 'validation')\n",
    "# set the random seeds to match eachother (to avoid overlapping of the images in\n",
    "# train and validation sets)\n",
    "\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                             seed=42)\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='validation',\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e4364d-4e79-4f34-ad2b-7a66447040ea",
   "metadata": {},
   "source": [
    "# Obtain Class names (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Af79dbaPaA6Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Af79dbaPaA6Z",
    "outputId": "c123d6d9-e133-4b73-819d-9d8e9e3ecc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea-earl-grey', 'tea-lemon']\n"
     ]
    }
   ],
   "source": [
    "# print some images\n",
    "# use .class_names attribute to retrieve the classes of the images from the dicrectories names\n",
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da411-d7f2-4394-93e2-cb4e97802a69",
   "metadata": {},
   "source": [
    "# Save model (JVM) with Base64 Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77e99-4c19-4c51-8bc9-7f9ddd08bff9",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8ac7404-0aa1-4e61-928c-efee862219a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea-earl-grey', 'tea-lemon']\n",
      "tf.Tensor([[b'tea-earl-grey' b'tea-lemon']], shape=(1, 2), dtype=string)\n",
      "tf.Tensor(b'tea-earl-grey', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(class_names)\n",
    "labels = tf.constant([class_names])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3219248-d436-42af-a996-387fd5bb1f83",
   "metadata": {},
   "source": [
    "### Load augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c2d1e9a-3735-4578-8df8-8896781e3b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction signature_wrapper(*, input_4)\n",
      "  Args:\n",
      "    input_4: float32 Tensor, shape=(None, 160, 160, 3)\n",
      "  Returns:\n",
      "    {'dense_1': <1>}\n",
      "      <1>: float32 Tensor, shape=(None, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tea_model_b64_jvm/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tea_model_b64_jvm/1/assets\n"
     ]
    }
   ],
   "source": [
    "smodel = tf.saved_model.load(\"../models/tea_model/1\")\n",
    "\n",
    "# This is the current signature, that only accepts image tensors as input\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "# print(signature)\n",
    "\n",
    "# obtain the key name of the output (typically 'dense_X')\n",
    "keyOutput = next(iter(signature.structured_outputs))\n",
    "\n",
    "@tf.function()\n",
    "def my_predict(image_b64):\n",
    "\n",
    "    # get content\n",
    "    content = image_b64[0]\n",
    "    \n",
    "    # decode image    \n",
    "    image = tf.image.decode_jpeg(content,channels=3)\n",
    "    # tf.compat.v1.enable_eager_execution()\n",
    "    \n",
    "    # resize image\n",
    "    image = tf.image.resize(image, [160, 160])\n",
    "    \n",
    "    # expand dimension to match signature\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    # execute prediction\n",
    "    prediction = signature(image)\n",
    "\n",
    "    # obtain index of maximum probability prediction\n",
    "    idx = tf.argmax(prediction[keyOutput],axis=1)\n",
    "    \n",
    "    # obtain the label for given index\n",
    "    label = labels[0][idx[0]]\n",
    "    label = tf.reshape(label,[1])\n",
    "    \n",
    "    # obtain probability from Tensor\n",
    "    probability = prediction[keyOutput][0,idx[0]]\n",
    "    probability = tf.reshape(tf.as_string(probability),[1])\n",
    "    \n",
    "    # combine result in String Tensor format with [label,probability]\n",
    "    result = tf.concat([label, probability], axis=0)\n",
    "    result = tf.reshape(result,[2, 1])\n",
    "    \n",
    "    # return result_tensor\n",
    "    return result\n",
    "\n",
    "# Create new signature, to read b64 images\n",
    "new_signature = my_predict.get_concrete_function(\n",
    "    image_b64=tf.TensorSpec(name=\"image_b64\", shape=[1], dtype=tf.string)\n",
    ")\n",
    "\n",
    "# Save model with Base64 input signature\n",
    "tf.saved_model.save(\n",
    "    smodel,\n",
    "    export_dir=\"../models/tea_model_b64_jvm/1\",\n",
    "    signatures=new_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f2fac-5d8e-40f6-a8cc-b53671c1e978",
   "metadata": {},
   "source": [
    "# Test Base64 Model with single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3a9b5d9-3bfc-48e6-b13a-efd0df2a1040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction signature_wrapper(*, image_b64)\n",
      "  Args:\n",
      "    image_b64: string Tensor, shape=(1,)\n",
      "  Returns:\n",
      "    {'output_0': <1>}\n",
      "      <1>: string Tensor, shape=(2, 1)\n"
     ]
    }
   ],
   "source": [
    "smodel = tf.saved_model.load(\"../models/tea_model_b64_jvm/1\")\n",
    "\n",
    "# Load model's signature\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbc0d5-70d9-4156-a6da-969a70a14aa4",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15e34858-5b74-4528-b631-9c66d8cfef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_0': <tf.Tensor: shape=(2, 1), dtype=string, numpy=\n",
      "array([[b'tea-lemon'],\n",
      "       [b'0.913074']], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "# testfile = \"../dataset/images/tea-earl-grey/PXL_20230803_124233750.MP.jpg\"\n",
    "testfile = \"../dataset/images/tea-lemon/PXL_20230803_153317298.jpg\"\n",
    "\n",
    "# load test image\n",
    "content = tf.io.read_file(testfile)\n",
    "\n",
    "# reshape to signature's expected dimensions\n",
    "content = tf.reshape(content, shape = [1])\n",
    "\n",
    "# print(tf.print(content, summarize=3))\n",
    "\n",
    "# obtain signature\n",
    "f = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "# run prediction\n",
    "myprediction = f(image_b64=content)\n",
    "print(myprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee7318-82e1-446a-88dd-0d714b9b610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc8a6b1-7ec7-4e65-9a4d-2ce5a1bb8834",
   "metadata": {},
   "source": [
    "# Testing Tensor manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "392a439b-87c9-4677-8d76-1c22726fb69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'one' b'two'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'three' b'four'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'two'], shape=(1,), dtype=string)\n",
      "tf.Tensor([b'four'], shape=(1,), dtype=string)\n",
      "tf.Tensor([b'two' b'four'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(['one', 'two'])\n",
    "b = tf.constant(['three', 'four'])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "# print(tf.reshape(a[1],[1]))\n",
    "a = tf.reshape(a[1],[1])\n",
    "b = tf.reshape(b[1],[1])\n",
    "print(a)\n",
    "print(b)\n",
    "# print(tf.concat([a[1],b[1]],axis=0))\n",
    "\n",
    "result = tf.concat([a, b], axis=0)\n",
    "print(result)\n",
    "# result = tf.concat([label, [tf.as_string(probability)]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b33d78-5e1a-4dc4-8b27-22a60894e320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Alpaca image classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
